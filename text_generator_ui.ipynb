{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaiShree-cloud/-Gradio-text-Generator/blob/main/text_generator_ui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch gradio\n"
      ],
      "metadata": {
        "id": "TYDGQuc83Myq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "-byGbhIX3PiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "EnKQ55F23Y5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length, temperature):\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_length=max_length,\n",
        "        temperature=temperature,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "lNsgdMnE3eVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ui = gr.Interface(\n",
        "    fn=generate_text,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=3, label=\"Enter Prompt\"),\n",
        "        gr.Slider(30, 150, value=80, label=\"Max Length\"),\n",
        "        gr.Slider(0.2, 1.2, value=0.7, label=\"Temperature\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Text\"),\n",
        "    title=\"GPT-2 Text Generator\",\n",
        "    description=\"Simple Generative AI Demo using GPT-2\"\n",
        ")\n",
        "\n",
        "ui.launch()\n"
      ],
      "metadata": {
        "id": "F9uVoFrx3h0y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}